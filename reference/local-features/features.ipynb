{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img: np.ndarray, title: str=\"\"):\n",
    "    '''\n",
    "    Display an opencv/numpy image.\n",
    "\n",
    "    Args:\n",
    "        img: np.ndarray, the image\n",
    "        title: str, title to display on the plot\n",
    "    '''\n",
    "    plt.imshow(img[...,::-1])\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "\n",
    "# OpenCV example\n",
    "#SCENE_IMAGE_PATH = 'box_in_scene.png'\n",
    "#QUERY_IMAGE_PATH = 'box.png'\n",
    "\n",
    "# Shell logo from openlogo\n",
    "#SCENE_IMAGE_PATH = '/data/openlogo/JPEGImages/shellimg000093.jpg'\n",
    "#QUERY_IMAGE_PATH = '/data/openlogo/JPEGImages/shellimg000130.jpg'\n",
    "\n",
    "# Oxford Buildings\n",
    "#  - Hertford College\n",
    "#SCENE_IMAGE_PATH = '/data/oxford-buildings/oxbuild_images/hertford_000034.jpg'\n",
    "#QUERY_IMAGE_PATH = '/data/oxford-buildings/oxbuild_images/hertford_000027.jpg'\n",
    "\n",
    "#  - Tower of the Five Orders\n",
    "#SCENE_IMAGE_PATH = '/data/oxford-buildings/oxbuild_images/bodleian_000037.jpg'\n",
    "#SCENE_IMAGE_PATH = '/data/oxford-buildings/oxbuild_images/bodleian_000000.jpg'\n",
    "#QUERY_IMAGE_PATH = '/data/oxford-buildings/oxbuild_images/bodleian_000041.jpg' # Fail\n",
    "\n",
    "MAX_SCENE_FEATURES = 10000\n",
    "MAX_QUERY_FEATURES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = cv2.imread(SCENE_IMAGE_PATH)\n",
    "display_image(scene, 'scene image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_gray = cv2.cvtColor(scene, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_shi_tomasi/py_shi_tomasi.html\n",
    "corners = cv2.goodFeaturesToTrack(scene_gray,maxCorners=2000,qualityLevel=0.01,minDistance=5)\n",
    "corners = np.int0(corners)\n",
    "display_img = scene.copy()\n",
    "\n",
    "# corner features are positional only\n",
    "# relies on optical flow to understand surroundings\n",
    "x, y = corners[0].ravel()\n",
    "print(f\"corners[0] = {corners[0]}, value = {scene_gray[x,y]}\")\n",
    "print(pd.DataFrame(data=scene_gray[x-2:x+3,y-2:y+3], index=range(y-2,y+3), columns=range(x-2,x+3)))\n",
    "\n",
    "for i in corners:\n",
    "    x,y = i.ravel()\n",
    "    cv2.circle(display_img,(x,y),5,[0,255,0],-1)\n",
    "\n",
    "display_image(display_img, 'good features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_orb/py_orb.html\n",
    "orb = cv2.ORB_create(nfeatures=MAX_SCENE_FEATURES)\n",
    "scene_kp, scene_des = orb.detectAndCompute(scene, None)\n",
    "\n",
    "print(f\"#kp={len(scene_kp)},#des={len(scene_des)}\")\n",
    "print(f\"{scene_kp[0].pt} {scene_kp[0].angle} {scene_kp[0].size}\")\n",
    "print(f\"len(des)={len(scene_des[0])}, des[0]={scene_des[0]}\")\n",
    "\n",
    "# SIFT features would be better in production\n",
    "# also increases the descriptor dimensionality to 128\n",
    "# which means better matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_img = cv2.drawKeypoints(scene, scene_kp, None, color=(0, 255, 0), flags=0)\n",
    "display_image(kp_img, \"ORB features on scene image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query By Example (QBE) aka Reverse Image Search\n",
    "query_img = cv2.imread(QUERY_IMAGE_PATH)\n",
    "display_image(query_img, 'query image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_gray = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_orb = cv2.ORB_create(nfeatures=MAX_QUERY_FEATURES)\n",
    "query_kp, query_des = query_orb.detectAndCompute(query_gray, None)\n",
    "\n",
    "print(f\"#kp={len(query_kp)},#des={len(query_des)}\")\n",
    "print(f\"{query_kp[0].pt} {query_kp[0].angle} {query_kp[0].size}\")\n",
    "print(f\"len(des)={len(query_des[0])}, des[0]={query_des[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_img = cv2.drawKeypoints(query_img, query_kp, None, color=(0, 255, 0), flags=0)\n",
    "display_image(kp_img, \"ORB features on query image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_matcher/py_matcher.html\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(query_des, scene_des)\n",
    "\n",
    "sorted_matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "def display_match_descriptors(query_descriptors, scene_descriptors, sorted_matches, index):\n",
    "    print(f\"query des: {query_descriptors[sorted_matches[index].queryIdx]}\")\n",
    "    print(f\"scene des: {scene_descriptors[sorted_matches[index].trainIdx]}\")\n",
    "    print(f\"hamming distance: {sorted_matches[index].distance}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "display_match_descriptors(query_des, scene_des, sorted_matches, 0)\n",
    "display_match_descriptors(query_des, scene_des, sorted_matches, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_img = cv2.drawMatches(query_img,query_kp,scene,scene_kp,sorted_matches[:50],None,flags=2)\n",
    "display_image(match_img, 'brute force feature matching')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve transform from query image to scene image\n",
    "dst_pts = np.float32([ scene_kp[m.trainIdx].pt for m in sorted_matches ]).reshape(-1,1,2)\n",
    "src_pts = np.float32([ query_kp[m.queryIdx].pt for m in sorted_matches ]).reshape(-1,1,2)\n",
    "\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(f\"perspective transform = \\n{M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform query image to scene image and blend\n",
    "warp = cv2.warpPerspective(query_img, M, (scene.shape[1], scene.shape[0]))\n",
    "blended = cv2.addWeighted(scene, 0.2, warp, 0.8, 0)\n",
    "display_image(blended, 'warped query image into scene')\n",
    "display_image(scene, 'original scene')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python361064bitvenvvenvc5dcc5567c844d39a25f157c6c5458e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}